{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "418f3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "configpath = str(config_path).replace('\\\\','/')\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# print(configpath)\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "# # Get the filename from command-line arguments\n",
    "filename = \"Top_5_Expense_Categories\"#sys.argv[1]\n",
    "\n",
    "# # Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "print(Excel_output)\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Top_5_Expense_Categories_report.csv\")    #(sys.stdin)\n",
    "if generate_content:\n",
    "    description_list = File_content_generator(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae755e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886cab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each output format and write directly if True\n",
    "if Excel_output:\n",
    "#     excel_path = config[f'{filename}']['Excel_output_path']\n",
    "    df.to_excel(datetime_folder /f'{filename}_report.xlsx', index=False)  # Write to Excel\n",
    "\n",
    "if csv_output:\n",
    "#     csv_path = config[f'{filename}']['csv_output_path']\n",
    "    df.to_csv(datetime_folder /f'{filename}_report.csv', index=False)  # Write to CSV\n",
    "\n",
    "if json_output:\n",
    "#     json_path = config[f'{filename}']['json_output_path']\n",
    "    df.to_json(datetime_folder /f'{filename}_report.json', orient='records', lines=True)  # Write to JSON\n",
    "\n",
    "if parquet_output:\n",
    "#     parquet_path = config[f'{filename}']['parquet_output_path']\n",
    "    df.to_parquet(datetime_folder /f'{filename}_report.parquet', index=False)  # Write to Parquet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e5b63c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/data/output/2024-10-23/2024-10-23_18-03-13\n"
     ]
    }
   ],
   "source": [
    "print(str(datetime_folder).replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4f9ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_output:\n",
    "    pdf_output_path = datetime_folder / f\"{filename}_Report.pdf\" \n",
    "    create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c7024f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "if word_output:\n",
    "    create_doc(datetime_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "    config[f'{filename}']['word_output_text_intro'], \n",
    "    description_list, \n",
    "    convert_to_tuple_format(df),\n",
    "    df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968d43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\data\\output\\s.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = current_directory / 'data' / 'output'\n",
    "print( output_path / 's.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c352e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f68425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\data\\output\\d_report.xlsx\n"
     ]
    }
   ],
   "source": [
    "filename = 'd'\n",
    "f = output_path /f'{filename}_report.xlsx'\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c7d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print entire config\n",
    "for section in config.sections():\n",
    "    print(f\"[{sction}]\")\n",
    "    for key, value in config.items(section):\n",
    "        print(f\"{key} = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9af7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/config/iconfig.ini'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(config_path).replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read('iconfig.ini')\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = \"Top_5_Expense_Categories\" #sys.argv[1]\n",
    "\n",
    "# Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/Top_5_Expense_Categories_report.csv\")\n",
    "if generate_content:\n",
    "    description_list = File_content_generator(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d76da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\n",
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\scripts\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Get the current script's parent directory (equivalent to current_directory in previous example)\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "print(current_directory)\n",
    "print(os.getcwd() )\n",
    "# # Get the path to the config file\n",
    "config_path = current_directory.parent / 'config' / 'iconfig.ini'\n",
    "\n",
    "# print(\"Config path:\", config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f7de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\n",
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\config\\iconfig.ini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "parent_directory = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(parent_directory)\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "print(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb330019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.\n",
    "output_path = current_directory / 'data' / 'output'/\n",
    "\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = sys.argv[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7cc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0eb2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "# filename = sys.argv[1]\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "output_path = current_directory / 'data' / 'output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629d59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "631564c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\AppData\\Local\\Temp\\ipykernel_23608\\823896618.py:52: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>card_type</th>\n",
       "      <th>growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad, India</td>\n",
       "      <td>Silver</td>\n",
       "      <td>83506240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city card_type      growth\n",
       "0  Ahmedabad, India    Silver  83506240.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from read_sql_file import *\n",
    "from configparser import RawConfigParser\n",
    "from setup_logging import *\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "sql_files_path = current_directory / 'sql'\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "filename = 'Year over Year Spend Growth.sql'#sys.argv[1]\n",
    "\n",
    "#'Top 5 Expense Categories.sql'\n",
    "def sql_analysis(filename):\n",
    "    # Set up logging for monitoring\n",
    "    \n",
    "\n",
    "    # Database connection parameters\n",
    "    server = config['SqlServer_Connection_Details']['server']\n",
    "    database = config['SqlServer_Connection_Details']['database']\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"#\"*50)\n",
    "        logging.info(f\"STEP 3 : Creating Reports\")\n",
    "        logging.info(f\"#\"*50)    \n",
    "        logging.info(\"Establishing database connection...\")\n",
    "        # Connect to the database\n",
    "        conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        logging.info(\"Database connection established successfully.\")\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Read the SQL query from the file\n",
    "        sql_query = read_sql_file(sql_files_path / filename)\n",
    "        logging.info(\"SQL filename: %s\", filename)\n",
    "        logging.info(\"SQL query read from file: %s\", sql_query)\n",
    "\n",
    "        # Execute the SQL query and load data into a DataFrame\n",
    "        df = pd.read_sql_query(sql_query, conn)\n",
    "        logging.info(\"SQL query executed successfully. Retrieved %d rows.\", len(df))\n",
    "#         df.to_csv(sys.stdout, index=False, header=True)\n",
    "        df.to_csv('Year over Year Spend Growth.csv', index=False, header=True)\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred: %s\", e)\n",
    "\n",
    "    finally:\n",
    "        # Ensure the database connection is closed\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "            logging.info(\"Cursor closed.\")\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            logging.info(\"Database connection closed.\")\n",
    "    return df  # Return the DataFrame\n",
    "sql_analysis(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61a6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = \"Year_over_Year_Spend_Growth\"#sys.argv[1]\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "output_path = current_directory / 'data' / 'output'\n",
    "\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you want to create a specific folder for the filename:\n",
    "filename_folder = datetime_folder / filename\n",
    "filename_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "\n",
    "\n",
    "# Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Year over Year Spend Growth.csv\")      \n",
    "df.to_csv(f'{filename}_OUTPUT.csv')\n",
    "if generate_content:\n",
    "    description_list = File_content_generator(df)\n",
    "\n",
    "\n",
    "# Check each output format and write directly if True\n",
    "if Excel_output:\n",
    "#     excel_path = config[f'{filename}']['Excel_output_path']\n",
    "    df.to_excel(filename_folder  /f'{filename}_report.xlsx', index=False)  # Write to Excel\n",
    "\n",
    "if csv_output:\n",
    "#     csv_path = config[f'{filename}']['csv_output_path']\n",
    "    df.to_csv(filename_folder /f'{filename}_report.csv', index=False)  # Write to CSV\n",
    "\n",
    "if json_output:\n",
    "#     json_path = config[f'{filename}']['json_output_path']\n",
    "    df.to_json(filename_folder /f'{filename}_report.json', orient='records', lines=True)  # Write to JSON\n",
    "\n",
    "if parquet_output:\n",
    "#     parquet_path = config[f'{filename}']['parquet_output_path']\n",
    "    df.to_parquet(filename_folder /f'{filename}_report.parquet', index=False)  # Write to Parquet\n",
    "\n",
    "\n",
    "# if pdf_output:\n",
    "#     pdf_output_path = filename_folder / f\"{filename}_Report.pdf\" \n",
    "#     create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n",
    "\n",
    "# # Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "# if word_output:\n",
    "#     create_doc(filename_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "#     config[f'{filename}']['word_output_text_intro'], \n",
    "#     description_list, \n",
    "#     convert_to_tuple_format(df),\n",
    "#     df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65de693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import os\n",
    "from convert_to_tuple_format import *\n",
    "\n",
    "# def File_content_generator(data):\n",
    "data = df\n",
    "co = cohere.ClientV2(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "The following data is extracted from credit card transactions sourced from https://www.kaggle.com/api/v1/datasets/download/thedevastator/analyzing-credit-card-spending-habits-in-india. \n",
    "\n",
    "Based on the expense categories and data below:\n",
    "{convert_to_tuple_format(data)}\n",
    "\n",
    "And Also Based on query:\n",
    "WITH YearlySpend AS (\n",
    "    SELECT \n",
    "        city,\n",
    "        card_type,\n",
    "        YEAR(transaction_date) AS year,\n",
    "        SUM(amount) AS total_spend\n",
    "    FROM \n",
    "        transactions\n",
    "    WHERE \n",
    "        YEAR(transaction_date) IN (2013, 2014)\n",
    "    GROUP BY \n",
    "        city, \n",
    "        card_type, \n",
    "        YEAR(transaction_date)\n",
    ")\n",
    "SELECT \n",
    "    y2014.city,\n",
    "    y2014.card_type,\n",
    "    (y2014.total_spend - COALESCE(y2013.total_spend, 0)) AS growth\n",
    "FROM \n",
    "    YearlySpend y2014\n",
    "LEFT JOIN \n",
    "    YearlySpend y2013 \n",
    "ON \n",
    "    y2014.city = y2013.city \n",
    "    AND y2014.card_type = y2013.card_type \n",
    "    AND y2013.year = 2013\n",
    "WHERE \n",
    "    y2014.year = 2014\n",
    "ORDER BY \n",
    "    growth DESC\n",
    "OFFSET 0 ROWS FETCH NEXT 1 ROW ONLY; -- SQL Server syntax for LIMIT\n",
    "\n",
    "\n",
    "Please provide:\n",
    "1. An overview highlighting the dominant categories along with their total spending and percentage contributions.\n",
    "2. Insights into budget allocation strategies and any suggestions for potential cost savings.\n",
    "3. Observations on consumer behavior trends, including potential correlations between spending categories.\n",
    "4. Recommendations for budget adjustments based on the analysis and any external factors that could influence spending habits.\n",
    "\n",
    "Provide the above insights as  dictionary for the answers for above.\n",
    "example for above: (\"Overview\",\"The five expense categories presented cover the essential aspects of daily life: Bills, Food, Fuel, Entertainment, and Grocery.\")\n",
    "also information about\n",
    "(\"Category Dominance\", \"\"),(\"Budget Allocation\", \"x\"),(\"Behavior Insights\",'x'). like for category dominace its findings based on data and will it  in place of 'x'. x should mention the findings of the title . example:\n",
    "(\"Category Dominance\", \"Housing and utilities are significant parts of most budgets.\")\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": {prompt}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Extracting only dictinary value from the generated response\n",
    "start = response.message.content[0].text.strip().find(\"{\")\n",
    "end = response.message.content[0].text.strip().rfind(\"}\") + 1\n",
    "# slicing the content based on the opening and closing '{}'\n",
    "dict_content = response.message.content[0].text.strip()[start:end]\n",
    "\n",
    "# Loading the content as a dictionary\n",
    "data_dict = json.loads(dict_content)\n",
    "\n",
    "# converting the content as a list of tuples to create a .docx and .pdf report using the content in a separate function.\n",
    "converted_data = [(key, value) for key, value in data_dict.items()]\n",
    "#     return converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468c5eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overview',\n",
       "  'The data provides an insight into the spending habits of credit card users in Ahmedabad, India, specifically those holding Silver cards. The total spend of over 8.35 crore rupees indicates a reliance on credit for essential expenses, with the potential for varying levels of debt accumulation among users.'),\n",
       " ('Category Dominance',\n",
       "  ['Essential expenses such as Bills dominate the spending, accounting for the majority of the total spend. This indicates that credit cards are being utilized for regular, recurring payments, which could result in long-term debt if not managed properly.',\n",
       "   'The second-highest spend is on Food, suggesting that dining out or ordering in is a common practice, potentially leaving room for cost-saving measures by encouraging home-cooked meals.',\n",
       "   'Fuel expenses are also significant, implying a reliance on personal vehicles for transportation, which could be influenced by the availability and convenience of public transport options.']),\n",
       " ('Budget Allocation',\n",
       "  ['A large portion of the budget is allocated to essential categories, which are non-negotiable expenses for cardholders. This leaves less room for discretionary spending, potentially impacting savings and investment opportunities.',\n",
       "   'To optimize budget allocation, cardholders could consider the following: Negotiating better rates for essential services to reduce bill amounts, without compromising on quality of life.',\n",
       "   'Setting spending limits for non-essential categories like Entertainment and Dining to ensure bills and other essential expenses are prioritized.',\n",
       "   'Utilizing rewards or cashback programs for essential spending categories to maximize returns on credit card usage.']),\n",
       " ('Behavior Insights',\n",
       "  ['There is a potential correlation between high spending on Bills and the use of credit cards for recurring payments, indicating a reliance on credit to manage essential expenses.',\n",
       "   'The spending on Food and Fuel suggests a preference for convenience and a higher standard of living, which could be influenced by cultural or societal factors.',\n",
       "   'The data does not provide insights into the breakdown of Food spending, i.e., dining out vs. groceries, which could impact budget analysis and savings strategies.',\n",
       "   'The absence of data on income levels makes it challenging to determine if spending habits are aligned with financial capabilities, potentially leading to debt accumulation.']),\n",
       " ('Recommendations',\n",
       "  ['To adjust the budget effectively, it is essential to analyze spending patterns over a more extended period and compare them across different demographic segments.',\n",
       "   'Encourage cardholders to prioritize essential expenses and provide financial literacy resources to ensure informed decision-making regarding credit usage.',\n",
       "   'Offer incentives or rewards for spending in specific categories, such as groceries or fuel, to help cardholders save money on essential expenses.',\n",
       "   'Analyze the impact of external factors, such as economic conditions or policy changes, on spending habits and adjust budget recommendations accordingly.',\n",
       "   'Consider the potential for debt accumulation and provide resources for financial planning and management to ensure long-term financial health.'])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e0752b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overview',\n",
       "  'The data provides an insight into the spending habits of an individual or a family based in Ahmedabad, India. With a total expenditure of â‚¹8,35,06,240, the expenses are dominated by a few key categories, which we will delve into further.'),\n",
       " ('Category Dominance',\n",
       "  \"The dominant categories in this dataset are 'Bills' and 'Fuel', together accounting for a significant proportion of the total spending. 'Bills' alone make up 57.3% of the total expenditure, while 'Fuel' contributes 24.5%. These two categories are essential and likely represent necessary expenses, such as housing, utilities, and transportation.\"),\n",
       " ('Budget Allocation',\n",
       "  \"The budget allocation seems to be heavily focused on covering the basic necessities, as indicated by the high spending on 'Bills' and 'Fuel'. This leaves a relatively smaller portion for other categories like 'Food', 'Entertainment', and 'Grocery'. To optimize spending, one could consider reviewing the 'Bills' category to identify areas where costs could be reduced without compromising on essential services. Given the high fuel expenditure, evaluating transportation options and considering fuel-efficient alternatives or negotiating corporate rates with fuel providers could be beneficial.\"),\n",
       " ('Behavior Insights',\n",
       "  \"The spending behavior reflected in the data suggests a focus on ensuring the coverage of essential services and utilities, which is a common strategy for budget allocation. However, the high fuel expenditure may indicate a reliance on private transportation, which could be an area to explore for potential cost savings or alternative arrangements. There might also be an opportunity to review spending patterns in the 'Food' and 'Entertainment' categories to ensure they align with the individual's or family's budget and lifestyle goals.\"),\n",
       " ('Recommendations',\n",
       "  \"Given the dominance of the 'Bills' category, a detailed analysis of this section could reveal opportunities for cost optimization. Negotiating rates with service providers, reviewing subscription plans, and exploring energy-efficient alternatives could help reduce this expense. Additionally, considering the high fuel costs, evaluating the efficiency of transportation methods and exploring options like carpooling or utilizing public transportation for certain trips could result in significant savings. For a more comprehensive analysis, external factors such as the local cost of living, family size, and income should also be taken into account.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e1f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_output:\n",
    "    pdf_output_path = filename_folder / f\"{filename}_Report.pdf\" \n",
    "    create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n",
    "\n",
    "# Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "if word_output:\n",
    "    create_doc(filename_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "    config[f'{filename}']['word_output_text_intro'], \n",
    "    description_list, \n",
    "    convert_to_tuple_format(df),\n",
    "    df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c823d052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ahmedabad, India', 'Silver', 83506240.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_tuple_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Year over Year Spend Growth.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b4fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "from read_sql_file import *\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = \"Year_over_Year_Spend_Growth\"#sys.argv[1]\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "output_path = current_directory / 'data' / 'output'\n",
    "sql_files_path = current_directory / 'sql'\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you want to create a specific folder for the filename:\n",
    "filename_folder = datetime_folder / filename\n",
    "filename_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "\n",
    "\n",
    "# Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "query_file_name = config[f'{filename}']['query_file_name']\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Year over Year Spend Growth.csv\") #(sys.stdin)\n",
    "# df = pd.to_csv(f'{filename}_OUTPUT'.csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce44f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH YearlySpend AS (\n",
      "    SELECT \n",
      "        city,\n",
      "        card_type,\n",
      "        YEAR(transaction_date) AS year,\n",
      "        SUM(amount) AS total_spend\n",
      "    FROM \n",
      "        transactions\n",
      "    WHERE \n",
      "        YEAR(transaction_date) IN (2013, 2014)\n",
      "    GROUP BY \n",
      "        city, \n",
      "        card_type, \n",
      "        YEAR(transaction_date)\n",
      ")\n",
      "SELECT \n",
      "    y2014.city,\n",
      "    y2014.card_type,\n",
      "    (y2014.total_spend - COALESCE(y2013.total_spend, 0)) AS growth\n",
      "FROM \n",
      "    YearlySpend y2014\n",
      "LEFT JOIN \n",
      "    YearlySpend y2013 \n",
      "ON \n",
      "    y2014.city = y2013.city \n",
      "    AND y2014.card_type = y2013.card_type \n",
      "    AND y2013.year = 2013\n",
      "WHERE \n",
      "    y2014.year = 2014\n",
      "ORDER BY \n",
      "    growth DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 1 ROW ONLY; -- SQL Server syntax for LIMIT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(read_sql_file(sql_files_path / query_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc9f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(read_sql_file(sql_files_path / query_file_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e489d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='08f911c6-5c97-4487-b8c2-bb76aa5c1a4d' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Here is a breakdown of the insights and recommendations based on the provided data and query:\\n\\n(\"Overview\", \"The data offers a glimpse into the spending habits of cardholders in Ahmedabad, India, specifically those holding Silver cards. The total spend for the year 2014 was 83,506,240, indicating a strong dominance in certain expense categories.\"),\\n\\n(\"Category Dominance\", \"The amount spent on \\'Bills\\' is substantial, taking the lion\\'s share of the budget at 36.7%. This is followed by \\'Food & Beverage\\' at 24.3%, indicating essential spending. \\'Fuel & Service Stations\\' takes up 18.5%, with \\'Entertainment\\' and \\'Grocery\\' trailing at 9.8% and 7.2% respectively. These top three categories contribute to over 80% of the total spending.\"),\\n\\n(\"Budget Allocation\", \"The budget allocation seems to be heavily tilted towards essential expenses, with \\'Bills\\' taking up more than a third of the total spend. This could be indicative of a practical and necessity-driven approach to budgeting. However, with a significant portion allocated to \\'Food & Beverage\\', there may be potential for cost savings or reallocation strategies.\"),\\n\\n(\"Behavior Insights\", \"There seems to be a trend towards convenience and essentialism. With \\'Fuel & Service Stations\\' in the top three categories, it suggests that cardholders prioritize mobility and vehicle maintenance. The spending on \\'Entertainment\\' could indicate a desire for leisure activities, but the relatively lower spend suggests a more conservative approach in this area. There may be a correlation between \\'Food & Beverage\\' and \\'Entertainment\\', suggesting that dining out or socializing over meals could be a common practice.\"),\\n\\n(\"Potential Cost Savings\", \"Given the high spend on \\'Food & Beverage\\', one strategy could be to encourage cardholders to cook at home or opt for more affordable dining options. Additionally, with \\'Bills\\' taking up a significant portion, negotiating better rates with service providers or switching to more cost-effective plans could result in substantial savings. For \\'Fuel & Service Stations\\', considering fuel-efficient vehicles or utilizing public transportation for certain trips may help reduce costs.\"),\\n\\n(\"Recommendations & External Factors\", \"Based on the analysis, we recommend a review of spending habits in the \\'Food & Beverage\\' category, as this could provide opportunities for cost savings without significantly impacting cardholders\\' lifestyles. Additionally, with the growing popularity of online streaming services, a shift from \\'Entertainment\\' spending towards these more affordable options could be suggested. External factors such as economic conditions, inflation, and the rise of remote work may influence future spending habits, particularly in the \\'Fuel\\' and \\'Entertainment\\' categories.\")\\n\\nThese insights provide a comprehensive analysis of the provided data, offering potential strategies for budget adjustments and highlighting consumer behavior trends.')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=542, output_tokens=590, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=740, output_tokens=590))\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate_content:\n\u001b[1;32m----> 2\u001b[0m     description_list \u001b[38;5;241m=\u001b[39m File_content_generator(df,read_sql_file(sql_files_path \u001b[38;5;241m/\u001b[39m query_file_name))\n",
      "File \u001b[1;32m~\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\scripts\\File_content_generator.py:49\u001b[0m, in \u001b[0;36mFile_content_generator\u001b[1;34m(data, query)\u001b[0m\n\u001b[0;32m     46\u001b[0m dict_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()[start:end]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Loading the content as a dictionary\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(dict_content)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# converting the content as a list of tuples to create a .docx and .pdf report using the content in a separate function.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m [(key, value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m data_dict\u001b[38;5;241m.\u001b[39mitems()]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "if generate_content:\n",
    "    description_list = File_content_generator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = response.message.content[0].text.strip().find(\"{\")\n",
    "end = response.message.content[0].text.strip().rfind(\"}\") + 1\n",
    "# slicing the content based on the opening and closing '{}'\n",
    "dict_content = response.message.content[0].text.strip()[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f15da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               city card_type      growth\n",
      "0  Ahmedabad, India    Silver  83506240.0 WITH YearlySpend AS (\n",
      "    SELECT \n",
      "        city,\n",
      "        card_type,\n",
      "        YEAR(transaction_date) AS year,\n",
      "        SUM(amount) AS total_spend\n",
      "    FROM \n",
      "        transactions\n",
      "    WHERE \n",
      "        YEAR(transaction_date) IN (2013, 2014)\n",
      "    GROUP BY \n",
      "        city, \n",
      "        card_type, \n",
      "        YEAR(transaction_date)\n",
      ")\n",
      "SELECT \n",
      "    y2014.city,\n",
      "    y2014.card_type,\n",
      "    (y2014.total_spend - COALESCE(y2013.total_spend, 0)) AS growth\n",
      "FROM \n",
      "    YearlySpend y2014\n",
      "LEFT JOIN \n",
      "    YearlySpend y2013 \n",
      "ON \n",
      "    y2014.city = y2013.city \n",
      "    AND y2014.card_type = y2013.card_type \n",
      "    AND y2013.year = 2013\n",
      "WHERE \n",
      "    y2014.year = 2014\n",
      "ORDER BY \n",
      "    growth DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 1 ROW ONLY; -- SQL Server syntax for LIMIT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "query = read_sql_file(sql_files_path / query_file_name)\n",
    "print(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9346779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import os\n",
    "from convert_to_tuple_format import *\n",
    "\n",
    "# def File_content_generator(data,query):\n",
    "data = df\n",
    "query = read_sql_file(sql_files_path / query_file_name)\n",
    "co = cohere.ClientV2(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "The following data is extracted from credit card transactions sourced from https://www.kaggle.com/api/v1/datasets/download/thedevastator/analyzing-credit-card-spending-habits-in-india. \n",
    "\n",
    "Based on the expense categories,data below and query:\n",
    "{convert_to_tuple_format(data)}\n",
    "query:\n",
    "{query}\n",
    "\n",
    "Please provide:\n",
    "1. An overview highlighting the dominant categories along with their total spending and percentage contributions.\n",
    "2. Insights into budget allocation strategies and any suggestions for potential cost savings.\n",
    "3. Observations on consumer behavior trends, including potential correlations between spending categories.\n",
    "4. Recommendations for budget adjustments based on the analysis and any external factors that could influence spending habits.\n",
    "\n",
    "Provide the above insights as  dictionary for the answers for above.\n",
    "example for above: (\"Overview\",\"The five expense categories presented cover the essential aspects of daily life: Bills, Food, Fuel, Entertainment, and Grocery.\")\n",
    "also information about\n",
    "(\"Category Dominance\", \"\"),(\"Budget Allocation\", \"x\"),(\"Behavior Insights\",'x'). like for category dominace its findings based on data and will it  in place of 'x'. x should mention the findings of the title . example:\n",
    "(\"Category Dominance\", \"Housing and utilities are significant parts of most budgets.\")\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": {prompt}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Extracting only dictinary value from the generated response\n",
    "start = response.message.content[0].text.strip().find(\"{\")\n",
    "end = response.message.content[0].text.strip().rfind(\"}\") + 1\n",
    "# slicing the content based on the opening and closing '{}'\n",
    "dict_content = response.message.content[0].text.strip()[start:end]\n",
    "\n",
    "# Loading the content as a dictionary\n",
    "data_dict = json.loads(dict_content)\n",
    "\n",
    "# converting the content as a list of tuples to create a .docx and .pdf report using the content in a separate function.\n",
    "converted_data = [(key, value) for key, value in data_dict.items()]\n",
    "#     return converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cfa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each output format and write directly if True\n",
    "if Excel_output:\n",
    "#     excel_path = config[f'{filename}']['Excel_output_path']\n",
    "    df.to_excel(filename_folder  /f'{filename}_report.xlsx', index=False)  # Write to Excel\n",
    "\n",
    "if csv_output:\n",
    "#     csv_path = config[f'{filename}']['csv_output_path']\n",
    "    df.to_csv(filename_folder /f'{filename}_report.csv', index=False)  # Write to CSV\n",
    "\n",
    "if json_output:\n",
    "#     json_path = config[f'{filename}']['json_output_path']\n",
    "    df.to_json(filename_folder /f'{filename}_report.json', orient='records', lines=True)  # Write to JSON\n",
    "\n",
    "if parquet_output:\n",
    "#     parquet_path = config[f'{filename}']['parquet_output_path']\n",
    "    df.to_parquet(filename_folder /f'{filename}_report.parquet', index=False)  # Write to Parquet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadecf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_output:\n",
    "    pdf_output_path = filename_folder / f\"{filename}_Report.pdf\" \n",
    "    create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n",
    "\n",
    "# Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "if word_output:\n",
    "    create_doc(filename_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "    config[f'{filename}']['word_output_text_intro'], \n",
    "    description_list, \n",
    "    convert_to_tuple_format(df),\n",
    "    df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
