{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "418f3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "configpath = str(config_path).replace('\\\\','/')\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# print(configpath)\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "# # Get the filename from command-line arguments\n",
    "filename = \"Top_5_Expense_Categories\"#sys.argv[1]\n",
    "\n",
    "# # Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "print(Excel_output)\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Top_5_Expense_Categories_report.csv\")    #(sys.stdin)\n",
    "if generate_content:\n",
    "    description_list = File_content_generator(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae755e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886cab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each output format and write directly if True\n",
    "if Excel_output:\n",
    "#     excel_path = config[f'{filename}']['Excel_output_path']\n",
    "    df.to_excel(datetime_folder /f'{filename}_report.xlsx', index=False)  # Write to Excel\n",
    "\n",
    "if csv_output:\n",
    "#     csv_path = config[f'{filename}']['csv_output_path']\n",
    "    df.to_csv(datetime_folder /f'{filename}_report.csv', index=False)  # Write to CSV\n",
    "\n",
    "if json_output:\n",
    "#     json_path = config[f'{filename}']['json_output_path']\n",
    "    df.to_json(datetime_folder /f'{filename}_report.json', orient='records', lines=True)  # Write to JSON\n",
    "\n",
    "if parquet_output:\n",
    "#     parquet_path = config[f'{filename}']['parquet_output_path']\n",
    "    df.to_parquet(datetime_folder /f'{filename}_report.parquet', index=False)  # Write to Parquet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e5b63c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/data/output/2024-10-23/2024-10-23_18-03-13\n"
     ]
    }
   ],
   "source": [
    "print(str(datetime_folder).replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4f9ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_output:\n",
    "    pdf_output_path = datetime_folder / f\"{filename}_Report.pdf\" \n",
    "    create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c7024f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "if word_output:\n",
    "    create_doc(datetime_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "    config[f'{filename}']['word_output_text_intro'], \n",
    "    description_list, \n",
    "    convert_to_tuple_format(df),\n",
    "    df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968d43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\data\\output\\s.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = current_directory / 'data' / 'output'\n",
    "print( output_path / 's.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c352e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f68425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\data\\output\\d_report.xlsx\n"
     ]
    }
   ],
   "source": [
    "filename = 'd'\n",
    "f = output_path /f'{filename}_report.xlsx'\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c7d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print entire config\n",
    "for section in config.sections():\n",
    "    print(f\"[{sction}]\")\n",
    "    for key, value in config.items(section):\n",
    "        print(f\"{key} = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9af7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/config/iconfig.ini'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(config_path).replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read('iconfig.ini')\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = \"Top_5_Expense_Categories\" #sys.argv[1]\n",
    "\n",
    "# Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/Top_5_Expense_Categories_report.csv\")\n",
    "if generate_content:\n",
    "    description_list = File_content_generator(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d76da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\n",
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\scripts\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Get the current script's parent directory (equivalent to current_directory in previous example)\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "print(current_directory)\n",
    "print(os.getcwd() )\n",
    "# # Get the path to the config file\n",
    "config_path = current_directory.parent / 'config' / 'iconfig.ini'\n",
    "\n",
    "# print(\"Config path:\", config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f7de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\n",
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\config\\iconfig.ini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "parent_directory = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(parent_directory)\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "print(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb330019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.\n",
    "output_path = current_directory / 'data' / 'output'/\n",
    "\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = sys.argv[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12957478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09d05bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "# filename = sys.argv[1]\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "output_path = current_directory / 'data' / 'output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5688b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5608865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\AppData\\Local\\Temp\\ipykernel_23608\\823896618.py:52: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>card_type</th>\n",
       "      <th>growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad, India</td>\n",
       "      <td>Silver</td>\n",
       "      <td>83506240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city card_type      growth\n",
       "0  Ahmedabad, India    Silver  83506240.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from read_sql_file import *\n",
    "from configparser import RawConfigParser\n",
    "from setup_logging import *\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "sql_files_path = current_directory / 'sql'\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "filename = 'Year over Year Spend Growth.sql'#sys.argv[1]\n",
    "\n",
    "#'Top 5 Expense Categories.sql'\n",
    "def sql_analysis(filename):\n",
    "    # Set up logging for monitoring\n",
    "    \n",
    "\n",
    "    # Database connection parameters\n",
    "    server = config['SqlServer_Connection_Details']['server']\n",
    "    database = config['SqlServer_Connection_Details']['database']\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"#\"*50)\n",
    "        logging.info(f\"STEP 3 : Creating Reports\")\n",
    "        logging.info(f\"#\"*50)    \n",
    "        logging.info(\"Establishing database connection...\")\n",
    "        # Connect to the database\n",
    "        conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        logging.info(\"Database connection established successfully.\")\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Read the SQL query from the file\n",
    "        sql_query = read_sql_file(sql_files_path / filename)\n",
    "        logging.info(\"SQL filename: %s\", filename)\n",
    "        logging.info(\"SQL query read from file: %s\", sql_query)\n",
    "\n",
    "        # Execute the SQL query and load data into a DataFrame\n",
    "        df = pd.read_sql_query(sql_query, conn)\n",
    "        logging.info(\"SQL query executed successfully. Retrieved %d rows.\", len(df))\n",
    "#         df.to_csv(sys.stdout, index=False, header=True)\n",
    "        df.to_csv('Year over Year Spend Growth.csv', index=False, header=True)\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred: %s\", e)\n",
    "\n",
    "    finally:\n",
    "        # Ensure the database connection is closed\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "            logging.info(\"Cursor closed.\")\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            logging.info(\"Database connection closed.\")\n",
    "    return df  # Return the DataFrame\n",
    "sql_analysis(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4766bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = \"Year_over_Year_Spend_Growth\"#sys.argv[1]\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "output_path = current_directory / 'data' / 'output'\n",
    "\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you want to create a specific folder for the filename:\n",
    "filename_folder = datetime_folder / filename\n",
    "filename_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "\n",
    "\n",
    "# Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Year over Year Spend Growth.csv\")      \n",
    "df.to_csv(f'{filename}_OUTPUT.csv')\n",
    "if generate_content:\n",
    "    description_list = File_content_generator(df)\n",
    "\n",
    "\n",
    "# Check each output format and write directly if True\n",
    "if Excel_output:\n",
    "#     excel_path = config[f'{filename}']['Excel_output_path']\n",
    "    df.to_excel(filename_folder  /f'{filename}_report.xlsx', index=False)  # Write to Excel\n",
    "\n",
    "if csv_output:\n",
    "#     csv_path = config[f'{filename}']['csv_output_path']\n",
    "    df.to_csv(filename_folder /f'{filename}_report.csv', index=False)  # Write to CSV\n",
    "\n",
    "if json_output:\n",
    "#     json_path = config[f'{filename}']['json_output_path']\n",
    "    df.to_json(filename_folder /f'{filename}_report.json', orient='records', lines=True)  # Write to JSON\n",
    "\n",
    "if parquet_output:\n",
    "#     parquet_path = config[f'{filename}']['parquet_output_path']\n",
    "    df.to_parquet(filename_folder /f'{filename}_report.parquet', index=False)  # Write to Parquet\n",
    "\n",
    "\n",
    "# if pdf_output:\n",
    "#     pdf_output_path = filename_folder / f\"{filename}_Report.pdf\" \n",
    "#     create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n",
    "\n",
    "# # Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "# if word_output:\n",
    "#     create_doc(filename_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "#     config[f'{filename}']['word_output_text_intro'], \n",
    "#     description_list, \n",
    "#     convert_to_tuple_format(df),\n",
    "#     df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2ed62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import os\n",
    "from convert_to_tuple_format import *\n",
    "\n",
    "# def File_content_generator(data):\n",
    "data = df\n",
    "co = cohere.ClientV2(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "The following data is extracted from credit card transactions sourced from https://www.kaggle.com/api/v1/datasets/download/thedevastator/analyzing-credit-card-spending-habits-in-india. \n",
    "\n",
    "Based on the expense categories and data below:\n",
    "{convert_to_tuple_format(data)}\n",
    "\n",
    "And Also Based on query:\n",
    "WITH YearlySpend AS (\n",
    "    SELECT \n",
    "        city,\n",
    "        card_type,\n",
    "        YEAR(transaction_date) AS year,\n",
    "        SUM(amount) AS total_spend\n",
    "    FROM \n",
    "        transactions\n",
    "    WHERE \n",
    "        YEAR(transaction_date) IN (2013, 2014)\n",
    "    GROUP BY \n",
    "        city, \n",
    "        card_type, \n",
    "        YEAR(transaction_date)\n",
    ")\n",
    "SELECT \n",
    "    y2014.city,\n",
    "    y2014.card_type,\n",
    "    (y2014.total_spend - COALESCE(y2013.total_spend, 0)) AS growth\n",
    "FROM \n",
    "    YearlySpend y2014\n",
    "LEFT JOIN \n",
    "    YearlySpend y2013 \n",
    "ON \n",
    "    y2014.city = y2013.city \n",
    "    AND y2014.card_type = y2013.card_type \n",
    "    AND y2013.year = 2013\n",
    "WHERE \n",
    "    y2014.year = 2014\n",
    "ORDER BY \n",
    "    growth DESC\n",
    "OFFSET 0 ROWS FETCH NEXT 1 ROW ONLY; -- SQL Server syntax for LIMIT\n",
    "\n",
    "\n",
    "Please provide:\n",
    "1. An overview highlighting the dominant categories along with their total spending and percentage contributions.\n",
    "2. Insights into budget allocation strategies and any suggestions for potential cost savings.\n",
    "3. Observations on consumer behavior trends, including potential correlations between spending categories.\n",
    "4. Recommendations for budget adjustments based on the analysis and any external factors that could influence spending habits.\n",
    "\n",
    "Provide the above insights as  dictionary for the answers for above.\n",
    "example for above: (\"Overview\",\"The five expense categories presented cover the essential aspects of daily life: Bills, Food, Fuel, Entertainment, and Grocery.\")\n",
    "also information about\n",
    "(\"Category Dominance\", \"\"),(\"Budget Allocation\", \"x\"),(\"Behavior Insights\",'x'). like for category dominace its findings based on data and will it  in place of 'x'. x should mention the findings of the title . example:\n",
    "(\"Category Dominance\", \"Housing and utilities are significant parts of most budgets.\")\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": {prompt}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Extracting only dictinary value from the generated response\n",
    "start = response.message.content[0].text.strip().find(\"{\")\n",
    "end = response.message.content[0].text.strip().rfind(\"}\") + 1\n",
    "# slicing the content based on the opening and closing '{}'\n",
    "dict_content = response.message.content[0].text.strip()[start:end]\n",
    "\n",
    "# Loading the content as a dictionary\n",
    "data_dict = json.loads(dict_content)\n",
    "\n",
    "# converting the content as a list of tuples to create a .docx and .pdf report using the content in a separate function.\n",
    "converted_data = [(key, value) for key, value in data_dict.items()]\n",
    "#     return converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc39698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overview',\n",
       "  'The data provides an insight into the spending habits of credit card users in Ahmedabad, India, specifically those holding Silver cards. The total spend of over 8.35 crore rupees indicates a reliance on credit for essential expenses, with the potential for varying levels of debt accumulation among users.'),\n",
       " ('Category Dominance',\n",
       "  ['Essential expenses such as Bills dominate the spending, accounting for the majority of the total spend. This indicates that credit cards are being utilized for regular, recurring payments, which could result in long-term debt if not managed properly.',\n",
       "   'The second-highest spend is on Food, suggesting that dining out or ordering in is a common practice, potentially leaving room for cost-saving measures by encouraging home-cooked meals.',\n",
       "   'Fuel expenses are also significant, implying a reliance on personal vehicles for transportation, which could be influenced by the availability and convenience of public transport options.']),\n",
       " ('Budget Allocation',\n",
       "  ['A large portion of the budget is allocated to essential categories, which are non-negotiable expenses for cardholders. This leaves less room for discretionary spending, potentially impacting savings and investment opportunities.',\n",
       "   'To optimize budget allocation, cardholders could consider the following: Negotiating better rates for essential services to reduce bill amounts, without compromising on quality of life.',\n",
       "   'Setting spending limits for non-essential categories like Entertainment and Dining to ensure bills and other essential expenses are prioritized.',\n",
       "   'Utilizing rewards or cashback programs for essential spending categories to maximize returns on credit card usage.']),\n",
       " ('Behavior Insights',\n",
       "  ['There is a potential correlation between high spending on Bills and the use of credit cards for recurring payments, indicating a reliance on credit to manage essential expenses.',\n",
       "   'The spending on Food and Fuel suggests a preference for convenience and a higher standard of living, which could be influenced by cultural or societal factors.',\n",
       "   'The data does not provide insights into the breakdown of Food spending, i.e., dining out vs. groceries, which could impact budget analysis and savings strategies.',\n",
       "   'The absence of data on income levels makes it challenging to determine if spending habits are aligned with financial capabilities, potentially leading to debt accumulation.']),\n",
       " ('Recommendations',\n",
       "  ['To adjust the budget effectively, it is essential to analyze spending patterns over a more extended period and compare them across different demographic segments.',\n",
       "   'Encourage cardholders to prioritize essential expenses and provide financial literacy resources to ensure informed decision-making regarding credit usage.',\n",
       "   'Offer incentives or rewards for spending in specific categories, such as groceries or fuel, to help cardholders save money on essential expenses.',\n",
       "   'Analyze the impact of external factors, such as economic conditions or policy changes, on spending habits and adjust budget recommendations accordingly.',\n",
       "   'Consider the potential for debt accumulation and provide resources for financial planning and management to ensure long-term financial health.'])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d111b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overview',\n",
       "  'The data provides an insight into the spending habits of an individual or a family based in Ahmedabad, India. With a total expenditure of ₹8,35,06,240, the expenses are dominated by a few key categories, which we will delve into further.'),\n",
       " ('Category Dominance',\n",
       "  \"The dominant categories in this dataset are 'Bills' and 'Fuel', together accounting for a significant proportion of the total spending. 'Bills' alone make up 57.3% of the total expenditure, while 'Fuel' contributes 24.5%. These two categories are essential and likely represent necessary expenses, such as housing, utilities, and transportation.\"),\n",
       " ('Budget Allocation',\n",
       "  \"The budget allocation seems to be heavily focused on covering the basic necessities, as indicated by the high spending on 'Bills' and 'Fuel'. This leaves a relatively smaller portion for other categories like 'Food', 'Entertainment', and 'Grocery'. To optimize spending, one could consider reviewing the 'Bills' category to identify areas where costs could be reduced without compromising on essential services. Given the high fuel expenditure, evaluating transportation options and considering fuel-efficient alternatives or negotiating corporate rates with fuel providers could be beneficial.\"),\n",
       " ('Behavior Insights',\n",
       "  \"The spending behavior reflected in the data suggests a focus on ensuring the coverage of essential services and utilities, which is a common strategy for budget allocation. However, the high fuel expenditure may indicate a reliance on private transportation, which could be an area to explore for potential cost savings or alternative arrangements. There might also be an opportunity to review spending patterns in the 'Food' and 'Entertainment' categories to ensure they align with the individual's or family's budget and lifestyle goals.\"),\n",
       " ('Recommendations',\n",
       "  \"Given the dominance of the 'Bills' category, a detailed analysis of this section could reveal opportunities for cost optimization. Negotiating rates with service providers, reviewing subscription plans, and exploring energy-efficient alternatives could help reduce this expense. Additionally, considering the high fuel costs, evaluating the efficiency of transportation methods and exploring options like carpooling or utilizing public transportation for certain trips could result in significant savings. For a more comprehensive analysis, external factors such as the local cost of living, family size, and income should also be taken into account.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca00cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_output:\n",
    "    pdf_output_path = filename_folder / f\"{filename}_Report.pdf\" \n",
    "    create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n",
    "\n",
    "# Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "if word_output:\n",
    "    create_doc(filename_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "    config[f'{filename}']['word_output_text_intro'], \n",
    "    description_list, \n",
    "    convert_to_tuple_format(df),\n",
    "    df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95b8dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ahmedabad, India', 'Silver', 83506240.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_tuple_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Year over Year Spend Growth.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5a28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from File_content_generator import *\n",
    "from create_doc import *\n",
    "from create_pdf import *\n",
    "from configparser import RawConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "from convert_to_tuple_format import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "from read_sql_file import *\n",
    "\n",
    "# Get the filename from command-line arguments\n",
    "filename = \"Year_over_Year_Spend_Growth\"#sys.argv[1]\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "config_path = current_directory / 'config' / 'iconfig.ini'\n",
    "output_path = current_directory / 'data' / 'output'\n",
    "sql_files_path = current_directory / 'sql'\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().date()\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format for folder name\n",
    "\n",
    "# Create date and datetime folders within the output path\n",
    "date_folder = output_path / str(current_date)\n",
    "datetime_folder = date_folder / current_datetime\n",
    "\n",
    "# Create the folders if they do not exist\n",
    "datetime_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you want to create a specific folder for the filename:\n",
    "filename_folder = datetime_folder / filename\n",
    "filename_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configuration\n",
    "config = RawConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "\n",
    "\n",
    "# Read output preferences from config\n",
    "Excel_output = config.getboolean(f'{filename}', 'Excel_output')\n",
    "csv_output = config.getboolean(f'{filename}', 'csv_output')\n",
    "json_output = config.getboolean(f'{filename}', 'json_output')\n",
    "parquet_output = config.getboolean(f'{filename}', 'parquet_output')\n",
    "pdf_output = config.getboolean(f'{filename}', 'pdf_output')\n",
    "word_output = config.getboolean(f'{filename}', 'word_output')\n",
    "generate_content = config.getboolean(f'{filename}', 'generate_content')\n",
    "query_file_name = config[f'{filename}']['query_file_name']\n",
    "\n",
    "# Read the input DataFrame from stdin\n",
    "df = pd.read_csv(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/Year over Year Spend Growth.csv\") #(sys.stdin)\n",
    "# df = pd.to_csv(f'{filename}_OUTPUT'.csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54da8612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH YearlySpend AS (\n",
      "    SELECT \n",
      "        city,\n",
      "        card_type,\n",
      "        YEAR(transaction_date) AS year,\n",
      "        SUM(amount) AS total_spend\n",
      "    FROM \n",
      "        transactions\n",
      "    WHERE \n",
      "        YEAR(transaction_date) IN (2013, 2014)\n",
      "    GROUP BY \n",
      "        city, \n",
      "        card_type, \n",
      "        YEAR(transaction_date)\n",
      ")\n",
      "SELECT \n",
      "    y2014.city,\n",
      "    y2014.card_type,\n",
      "    (y2014.total_spend - COALESCE(y2013.total_spend, 0)) AS growth\n",
      "FROM \n",
      "    YearlySpend y2014\n",
      "LEFT JOIN \n",
      "    YearlySpend y2013 \n",
      "ON \n",
      "    y2014.city = y2013.city \n",
      "    AND y2014.card_type = y2013.card_type \n",
      "    AND y2013.year = 2013\n",
      "WHERE \n",
      "    y2014.year = 2014\n",
      "ORDER BY \n",
      "    growth DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 1 ROW ONLY; -- SQL Server syntax for LIMIT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(read_sql_file(sql_files_path / query_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847338c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(read_sql_file(sql_files_path / query_file_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ed3e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='8ed8979d-5bd8-4545-98bc-76633b858517' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Here is a response to your request in the format of a dictionary:\\n\\n{\"Overview\": \"The data provided offers a glimpse into the spending habits of an individual or a household based in Ahmedabad, India. With a total expenditure of ₹8,35,06,240, the budget appears to be geared towards essential categories, indicating a practical approach to finances. This single data point provides a snapshot of their spending behavior and category priorities.\",\\n \"Category Dominance\": \"The dominant category, \\'Bills\\', accounts for the majority of the total spending, with a significant amount of ₹8,35,06,240. This category likely includes essential utilities such as electricity, water, and internet services, suggesting that the budget holder prioritizes covering these necessary expenses. The \\'Silver\\' category, which could represent a specific type of credit card or membership, also stands out with the same amount, indicating a potential focus on benefits or rewards associated with this category.\",\\n \"Spending Percentage\": \"While the data provided does not include a detailed breakdown of percentages, a simple calculation reveals that the \\'Bills\\' and \\'Silver\\' categories each contribute 100% to the total spending, indicating a heavy focus on these areas. This suggests that the budget holder aims to ensure these essential expenses are fully covered first before allocating funds elsewhere.\",\\n \"Budget Allocation\": \"The budget appears to be heavily allocated towards essential categories, which is a practical strategy to ensure stability in covering necessary expenses. However, the absence of other varied spending categories indicates a potential opportunity to introduce a more diverse budget allocation. Introducing a balanced approach to discretionary spending, such as entertainment, dining out, or travel, could enhance the budget holder\\'s lifestyle without compromising financial stability.\",\\n \"Behavior Insights\": \"The concentration of spending in the \\'Bills\\' and \\'Silver\\' categories suggests a responsible and pragmatic approach to finances. This behavior is often indicative of a long-term mindset, where budget holders prioritize essential expenses to maintain a consistent standard of living. The absence of other categories could also imply a disciplined spending behavior, where non-essential purchases are carefully considered and potentially deferred.\",\\n \"Potential Correlations\": \"A strong correlation may exist between the \\'Bills\\' and \\'Silver\\' categories, indicating that certain benefits or rewards are linked to the timely payment of bills. This could be in the form of loyalty programs, cashback incentives, or membership perks. Analyzing the specific nature of these categories and their correlation could uncover opportunities for optimized spending strategies and enhanced benefits.\",\\n \"Cost Savings\": \"Reviewing the breakdown of the \\'Bills\\' category could reveal opportunities for cost savings. Negotiating rates with service providers, opting for energy-efficient solutions, or exploring alternative plans could help reduce overall utility expenses. Additionally, assessing the benefits associated with the \\'Silver\\' category could identify areas where the budget holder can maximize rewards or take advantage of exclusive promotions to stretch their rupee further.\",\\n \"Budget Adjustments\": \"Considering the focus on essential categories, introducing a dedicated emergency fund could provide peace of mind and financial security. Allocating a small percentage of the budget towards this fund each month would prepare the budget holder for unexpected expenses. Additionally, given the absence of discretionary spending categories, allocating a modest budget for entertainment or leisure activities could positively impact their overall well-being.\"}\\n\\nPlease note that the insights provided are based on the limited data shared and are intended to be preliminary observations. A more comprehensive analysis would be possible with additional data points and detailed category breakdowns.')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=281, output_tokens=719, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=479, output_tokens=719))\n"
     ]
    }
   ],
   "source": [
    "if generate_content:\n",
    "    description_list = File_content_generator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc86d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = response.message.content[0].text.strip().find(\"{\")\n",
    "end = response.message.content[0].text.strip().rfind(\"}\") + 1\n",
    "# slicing the content based on the opening and closing '{}'\n",
    "dict_content = response.message.content[0].text.strip()[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b2d162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               city card_type      growth\n",
      "0  Ahmedabad, India    Silver  83506240.0 WITH YearlySpend AS (\n",
      "    SELECT \n",
      "        city,\n",
      "        card_type,\n",
      "        YEAR(transaction_date) AS year,\n",
      "        SUM(amount) AS total_spend\n",
      "    FROM \n",
      "        transactions\n",
      "    WHERE \n",
      "        YEAR(transaction_date) IN (2013, 2014)\n",
      "    GROUP BY \n",
      "        city, \n",
      "        card_type, \n",
      "        YEAR(transaction_date)\n",
      ")\n",
      "SELECT \n",
      "    y2014.city,\n",
      "    y2014.card_type,\n",
      "    (y2014.total_spend - COALESCE(y2013.total_spend, 0)) AS growth\n",
      "FROM \n",
      "    YearlySpend y2014\n",
      "LEFT JOIN \n",
      "    YearlySpend y2013 \n",
      "ON \n",
      "    y2014.city = y2013.city \n",
      "    AND y2014.card_type = y2013.card_type \n",
      "    AND y2013.year = 2013\n",
      "WHERE \n",
      "    y2014.year = 2014\n",
      "ORDER BY \n",
      "    growth DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 1 ROW ONLY; -- SQL Server syntax for LIMIT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "query = read_sql_file(sql_files_path / query_file_name)\n",
    "print(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308ac000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import os\n",
    "from convert_to_tuple_format import *\n",
    "\n",
    "# def File_content_generator(data,query):\n",
    "data = df\n",
    "query = read_sql_file(sql_files_path / query_file_name)\n",
    "co = cohere.ClientV2(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "The following data is extracted from credit card transactions sourced from https://www.kaggle.com/api/v1/datasets/download/thedevastator/analyzing-credit-card-spending-habits-in-india. \n",
    "\n",
    "Based on the expense categories,data below and query:\n",
    "{convert_to_tuple_format(data)}\n",
    "query:\n",
    "{query}\n",
    "\n",
    "Please provide:\n",
    "1. An overview highlighting the dominant categories along with their total spending and percentage contributions.\n",
    "2. Insights into budget allocation strategies and any suggestions for potential cost savings.\n",
    "3. Observations on consumer behavior trends, including potential correlations between spending categories.\n",
    "4. Recommendations for budget adjustments based on the analysis and any external factors that could influence spending habits.\n",
    "\n",
    "Provide the above insights as  dictionary for the answers for above.\n",
    "example for above: (\"Overview\",\"The five expense categories presented cover the essential aspects of daily life: Bills, Food, Fuel, Entertainment, and Grocery.\")\n",
    "also information about\n",
    "(\"Category Dominance\", \"\"),(\"Budget Allocation\", \"x\"),(\"Behavior Insights\",'x'). like for category dominace its findings based on data and will it  in place of 'x'. x should mention the findings of the title . example:\n",
    "(\"Category Dominance\", \"Housing and utilities are significant parts of most budgets.\")\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": {prompt}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Extracting only dictinary value from the generated response\n",
    "start = response.message.content[0].text.strip().find(\"{\")\n",
    "end = response.message.content[0].text.strip().rfind(\"}\") + 1\n",
    "# slicing the content based on the opening and closing '{}'\n",
    "dict_content = response.message.content[0].text.strip()[start:end]\n",
    "\n",
    "# Loading the content as a dictionary\n",
    "data_dict = json.loads(dict_content)\n",
    "\n",
    "# converting the content as a list of tuples to create a .docx and .pdf report using the content in a separate function.\n",
    "converted_data = [(key, value) for key, value in data_dict.items()]\n",
    "#     return converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each output format and write directly if True\n",
    "if Excel_output:\n",
    "#     excel_path = config[f'{filename}']['Excel_output_path']\n",
    "    df.to_excel(filename_folder  /f'{filename}_report.xlsx', index=False)  # Write to Excel\n",
    "\n",
    "if csv_output:\n",
    "#     csv_path = config[f'{filename}']['csv_output_path']\n",
    "    df.to_csv(filename_folder /f'{filename}_report.csv', index=False)  # Write to CSV\n",
    "\n",
    "if json_output:\n",
    "#     json_path = config[f'{filename}']['json_output_path']\n",
    "    df.to_json(filename_folder /f'{filename}_report.json', orient='records', lines=True)  # Write to JSON\n",
    "\n",
    "if parquet_output:\n",
    "#     parquet_path = config[f'{filename}']['parquet_output_path']\n",
    "    df.to_parquet(filename_folder /f'{filename}_report.parquet', index=False)  # Write to Parquet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73511b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_output:\n",
    "    pdf_output_path = filename_folder / f\"{filename}_Report.pdf\" \n",
    "    create_pdf(str(pdf_output_path), f\"{filename.replace('_',' ')}\", description_list, df)\n",
    "\n",
    "# Here the parameter 4 passed in create_doc is genereated by an llm model(cohere)    \n",
    "if word_output:\n",
    "    create_doc(filename_folder /f'{filename}_Report.docx', f\"{filename.replace('_',' ')}\", \n",
    "    config[f'{filename}']['word_output_text_intro'], \n",
    "    description_list, \n",
    "    convert_to_tuple_format(df),\n",
    "    df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01791aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\data\\LOGS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "current_directory = Path(os.getcwd()).resolve().parent\n",
    "log_path = current_directory / 'data' / 'LOGS' \n",
    "\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bf80c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Programming\\Data Engineering Projects\\Data Engineering Project 2\\data\\LOGS\\2024-10-24\n"
     ]
    }
   ],
   "source": [
    "# def get_latest_log_file():\n",
    "    # Define the path for today's log directory\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "log_dir = os.path.join(log_path, today_date)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75b7681",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (4191352886.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    return None\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Get all log files in the directory\n",
    "log_files = [logfile for logfile in os.listdir(log_dir) if logfile.endswith('.log')]\n",
    "\n",
    "# If there are no log files, return None\n",
    "if not log_files:\n",
    "    return None\n",
    "\n",
    "# Get the full path of the most recently created log file\n",
    "latest_log_file = max(\n",
    "    [os.path.join(log_dir, f) for f in log_files],\n",
    "    key=os.path.getctime\n",
    ")\n",
    "print(latest_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project-root/\n",
    "│\n",
    "├── data/                           # Directory to store datasets or generated files\n",
    "│   ├── input/                     # Input datasets (CSV, Excel, JSON, etc.)\n",
    "│   ├── output/                    # Generated outputs in CSV, Excel, JSON, PDF, etc.\n",
    "│   └── logs/                      # Directory for log files\n",
    "│\n",
    "├── sql/                           # Directory to store SQL scripts\n",
    "│   ├── Average_Spend_Per_Transaction_by_Card_Type.sql\n",
    "│   ├── Cumulative_Spend_by_City.sql\n",
    "│   ├── Fastest_Growth_in_Spending.sql\n",
    "│   ├── Highest_Spending_Gender.sql\n",
    "│   ├── Spend_by_Gender_Across_Cities.sql\n",
    "│   ├── Spend_Distribution_Across_Card_Types.sql\n",
    "│   ├── Top_5_Expense_Categories.sql\n",
    "│   ├── Weekend_vs_Weekday_Transaction_Patterns.sql\n",
    "│   └── Year_over_Year_Spend_Growth.sql\n",
    "│\n",
    "├── config/                        # Directory for configuration files\n",
    "│   ├── iconfig.ini                # Main config file with settings for outputs\n",
    "│\n",
    "├── scripts/                       # Directory to store all Python scripts\n",
    "│   ├── file_content_generator.py  # File generator script\n",
    "│   ├── create_doc.py              # Word document generation script\n",
    "│   ├── create_pdf.py              # PDF generation script\n",
    "│   ├── sql_analysis.py            # Main analysis script using SQL\n",
    "│   ├── setup_logging.py            # Logging setup script\n",
    "│   ├── read_sql_file.py           # Script to read SQL files for analysis\n",
    "│   ├── output_generation.py        # Script for generating various output formats\n",
    "│   ├── kaggle_data_download.py     # Script to download datasets from Kaggle\n",
    "│   ├── table_creation_and_data_loading.py  # Script for creating tables and loading data\n",
    "│   ├── get_latest_log_file.py      # Script to retrieve the latest log file\n",
    "│   └── convert_to_tuple_format.py   # Script to convert data to tuple format\n",
    "│ \n",
    "├── docs/                          # Documentation related files\n",
    "│   ├── project_report.docx        # Final project report (can be dynamically generated)\n",
    "│   └── README.md                  # Documentation for the project setup and usage\n",
    "│\n",
    "├── .gitignore                     # Git ignore file for hiding unwanted files in version control\n",
    "└── README.md                      # General project documentation (overview, setup, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fca409c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de50df54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'setup_logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m setup_logging\n",
      "\u001b[1;31mNameError\u001b[0m: name 'setup_logging' is not defined"
     ]
    }
   ],
   "source": [
    "setup_logging\n",
    "read_sql_file\n",
    "Output_Generation\n",
    "Kaggle_data_download\n",
    "Table_Creation_and_data_loading\n",
    "get_latest_log_file\n",
    "convert_to_tuple_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d514c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_tuple_format.py\n",
      "create_doc.py\n",
      "create_pdf.py\n",
      "File_content_generator.py\n",
      "get_latest_log_file.py\n",
      "Kaggle_data_download.py\n",
      "Output_Generation.py\n",
      "read_sql_file.py\n",
      "setup_logging.py\n",
      "sql_analysis.py\n",
      "Table_Creation_and_data_loading.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "f = []\n",
    "for a in os.listdir(\"C:/Users/akhil/Programming/Data Engineering Projects/Data Engineering Project 2/scripts/\"):\n",
    "    if a.endswith('.py') and 'OLD' not in a:\n",
    "        print(a)\n",
    "        f.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765d26e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convert_to_tuple_format.py',\n",
       " 'create_doc.py',\n",
       " 'create_pdf.py',\n",
       " 'File_content_generator.py',\n",
       " 'get_latest_log_file.py',\n",
       " 'Kaggle_data_download.py',\n",
       " 'Output_Generation.py',\n",
       " 'read_sql_file.py',\n",
       " 'setup_logging.py',\n",
       " 'sql_analysis.py',\n",
       " 'Table_Creation_and_data_loading.py']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57686a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional presentation created successfully!\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.util import Inches, Pt\n",
    "\n",
    "def set_title_style(title_shape):\n",
    "    \"\"\"Set the style for the title text.\"\"\"\n",
    "    title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
    "    title_shape.text_frame.paragraphs[0].font.bold = True\n",
    "    title_shape.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)\n",
    "    title_shape.fill.solid()\n",
    "    title_shape.fill.fore_color.rgb = RGBColor(0, 102, 204)  # Background color for title slide\n",
    "\n",
    "def set_content_style(content_shape):\n",
    "    \"\"\"Set the style for the content text.\"\"\"\n",
    "    for paragraph in content_shape.text_frame.paragraphs:\n",
    "        paragraph.font.size = Pt(20)\n",
    "        paragraph.font.color.rgb = RGBColor(0, 0, 0)\n",
    "        paragraph.space_after = Pt(14)\n",
    "\n",
    "def create_presentation():\n",
    "    # Create a Presentation object\n",
    "    prs = Presentation()\n",
    "\n",
    "    # Title Slide\n",
    "    slide_title = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "    title = slide_title.shapes.title\n",
    "    subtitle = slide_title.placeholders[1]\n",
    "    title.text = \"Credit Card Transaction Analysis\"\n",
    "    subtitle.text = \"An Insight into Consumer Spending Behavior\"\n",
    "    \n",
    "    # Apply custom styling to title slide\n",
    "    set_title_style(title)\n",
    "    set_title_style(subtitle)\n",
    "\n",
    "    # Slide 1: Overview\n",
    "    slide_overview = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    title = slide_overview.shapes.title\n",
    "    content = slide_overview.placeholders[1]\n",
    "    title.text = \"Project Overview\"\n",
    "    content.text = (\"This project analyzes credit card transaction data from Kaggle, \"\n",
    "                    \"focusing on consumer spending habits in India. \"\n",
    "                    \"The analysis provides insights into spending categories and consumer behavior trends.\")\n",
    "    \n",
    "    # Apply custom styling to content\n",
    "    set_content_style(content)\n",
    "\n",
    "    # Slide 2: Key Insights\n",
    "    slide_insights = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    title = slide_insights.shapes.title\n",
    "    content = slide_insights.placeholders[1]\n",
    "    title.text = \"Key Insights\"\n",
    "    content.text = (\"1. Average spend per transaction by card type.\\n\"\n",
    "                    \"2. Cumulative spending trends by city.\\n\"\n",
    "                    \"3. Gender-based spending habits.\")\n",
    "    \n",
    "    # Apply custom styling to content\n",
    "    set_content_style(content)\n",
    "\n",
    "    # Slide 3: Data Visualization\n",
    "    slide_viz = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    title = slide_viz.shapes.title\n",
    "    content = slide_viz.placeholders[1]\n",
    "    title.text = \"Data Visualization\"\n",
    "    content.text = \"Visualizations help in understanding spending patterns more effectively.\"\n",
    "    \n",
    "    # Apply custom styling to content\n",
    "    set_content_style(content)\n",
    "\n",
    "    # Slide 4: Conclusion\n",
    "    slide_conclusion = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    title = slide_conclusion.shapes.title\n",
    "    content = slide_conclusion.placeholders[1]\n",
    "    title.text = \"Conclusion\"\n",
    "    content.text = (\"The analysis reveals significant trends in consumer spending, \"\n",
    "                    \"providing valuable insights for future marketing strategies.\")\n",
    "    \n",
    "    # Apply custom styling to content\n",
    "    set_content_style(content)\n",
    "\n",
    "    # Optionally, you can add a logo or image\n",
    "    # logo = slide_conclusion.shapes.add_picture('path/to/logo.png', Inches(1), Inches(1), width=Inches(2))\n",
    "\n",
    "    # Save the presentation\n",
    "    prs.save('Credit_Card_Transaction_Analysis_Professional.pptx')\n",
    "    print(\"Professional presentation created successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_presentation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49825065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-pptx\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\akhil\\anaconda3\\lib\\site-packages (from python-pptx) (10.2.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\akhil\\anaconda3\\lib\\site-packages (from python-pptx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\akhil\\anaconda3\\lib\\site-packages (from python-pptx) (4.12.2)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "   ---------------------------------------- 0.0/472.8 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/472.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/472.8 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 122.9/472.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 348.2/472.8 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 472.8/472.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 159.9/159.9 kB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: XlsxWriter, python-pptx\n",
      "Successfully installed XlsxWriter-3.2.0 python-pptx-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-pptx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014fa74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
